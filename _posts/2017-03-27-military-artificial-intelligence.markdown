---
layout: post
title: "Military Artificial Intelligence"
date: 2017-03-27 21:01:00
categories: singularity
---

There has [been some discussion recently](http://marginalrevolution.com/marginalrevolution/2017/03/ai-really-help-defense-military-situations.html) about artificial intelligence in military applications. In particular, [Eric Schmidt posed an interesting theory](http://foreignpolicy.com/2017/03/22/army-chief-time-to-prepare-for-urban-war/):

> I interviewed Eric Schmidt of Google fame, who has been leading a civilian panel of technologists looking at how the Pentagon can better innovate. He said something I hadnâ€™t heard before, which is that artificial intelligence helps the defense better than the offense. This is because AI always learns, and so constantly monitors patterns of incoming threats. This made me think that the next big war will be more like World War I (when the defense dominated) than World War II (when the offense did).

To me, something doesn't quite sit right about this. It feels like this is [reasoning by analogy instead of reasoning from first principles](http://jamesclear.com/first-principles). It seems like World-War-I-style defensive warfare happens when there is a fundamental advantage from sitting in one physical location, like in medieval times before artillery got powerful enough to defeat physical walls, rather than when patterns of incoming threats are easy to monitor.

Disclaimer: my expertise is not military. I did listen to [Dan Carlin's podcast on World War I](http://www.dancarlin.com/product/hardcore-history-50-blueprint-for-armageddon-i/) though. Best 20-hour podcast ever.

So it's not really fair for me to just snipe at Eric Schmidt. I should offer a theory of, what will artificial intelligence do to the military? What sort of military operation will it make more powerful?

I think the first question to ask is whether "offense and defense" is the right way to break down future wars. In World War I and World War II, you had an offense and a defense. Nowadays, the sides are more likely to be "the state" versus "the terrorists". If you're interested in this shift, a bunch of military types seem to refer to this as the rise of [fourth-generation warfare](https://en.wikipedia.org/wiki/Fourth-generation_warfare).

> Fourth-generation warfare (4GW) is conflict characterized by a blurring of the lines between war and politics, combatants and civilians.
>
> The term was first used in 1989 by a team of United States analysts, including paleoconservative William S. Lind, to describe warfare's return to a decentralized form. In terms of generational modern warfare, the fourth generation signifies the nation states' loss of their near-monopoly on combat forces, returning to modes of conflict common in pre-modern times.

The first bits of AI in war are already happening, with the rise of drone warfare. So far, drone warfare is a big advantage for "the state". While [ISIS is using more and more drones](http://www.defenseone.com/technology/2017/01/drones-isis/134542/), for now there's still a massive AI advantage that goes to the side which can deploy more capital.

It's not clear if this trend will continue, though. If drones get cheaper and cheaper, we could end up in a world where the state and the terrorists both have access to drones of similar quality. What would warfare look like if the terrorists had just as many Predator drones as the government, because the parts cost $100 and you can make them in any back alley with a 3D printer? If the drone was the size of a paper airplane, and you could give it a few pictures of any person and have it seek out the target? If assassinations were cheap on each side, the forces of chaos seem like they would rule the day. So at that point it seems like AI would be an advantage for the terrorists. It's hard for me to imagine how any society could live under those conditions, really. What would society resort to in that world?

It seems like a recipe for totalitarian crackdown. Make 3D printers illegal, record video on every street corner, record video inside every house, track every object everywhere, it's the only way to stay safe. If we have to go that far, then it seems like AI will be an advantage to the state. It's the only way to make administration of the totalitarian state practical. Not really a pleasant world though. Hopefully something is wrong about my projection here.

Besides drones, I can imagine military AI becoming relevant for cybersecurity. This one is a bit more far out - we are a lot better at the AI you need for robotics, than the AI you need to hack into a computer system. So would AI be good for the black hats or for the white hats? I can imagine an AI that's really good at finding flaws in a computer system, but I can also imagine that same AI scanning your defenses like a souped up Valgrind checking for the existence of any flaws. I guess I could see this going either way.

So overall, the military status quo is pretty good. The world is not devolved into warfare and chaos, and it seems nice to keep it that way. Unfortunately, it seems to me like military AI is quite likely to take things in the wrong direction. I don't think there's a practical way to get the world to not adopt a new military technology; the same arms race mechanic applies now as [it did in 1914](http://encyclopedia.1914-1918-online.net/article/arms_race_prior_to_1914_armament_policy). Wish I had a way to end this post on a positive note, but maybe I should just leave the reader hanging with a vague sense of unease. Enjoy!
